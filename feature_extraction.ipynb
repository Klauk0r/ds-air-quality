{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import pipeline Stuff\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rseed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Data\n",
    "df=pd.read_csv(\"./data/Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to replace spaces in the string (i.e. missings) with NaN\n",
    "def replace_nan(x):\n",
    "    if x==\" \":\n",
    "        return np.nan\n",
    "    else :\n",
    "        return float(x)\n",
    "\n",
    "# define list of feature names\n",
    "features=[\"temp\",\"precip\",\"rel_humidity\",\"wind_dir\",\"wind_spd\",\"atmos_press\"]\n",
    "\n",
    "\n",
    "for feature in features : \n",
    "    # first replace every 'nan' in a cell with an empty space, split using comma, and then apply replace_nan function on every item\n",
    "    df[feature]=df[feature].apply(lambda x: [ replace_nan(X) for X\n",
    " in x.replace(\"nan\",\" \").split(\",\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn wind data into sensible format\n",
    "df[\"wind_dir_x\"] = df.wind_dir.apply(lambda x: list(np.cos(np.array(x) * np.pi /180)))\n",
    "df[\"wind_dir_y\"] = df.wind_dir.apply(lambda x: list(np.sin(np.array(x) * np.pi /180)))\n",
    "df.drop(\"wind_dir\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def fit_time(time_series, return_fit_curve=False):\n",
    "    \"\"\"gets a time series, must be hourly, calculates the starting time from fitting a sine on it.\n",
    "\n",
    "    Args:\n",
    "        time_series (list): a list describing the time series\n",
    "        return_fit_curve (bool, optional): tells, weather it should return the x, y and fitted y values. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        value: the phase angle describing the time of day, ranging from 0 to 2 pi\n",
    "        OR also the x and y used for fitting and the fitted y.\n",
    "    \"\"\"\n",
    "    # get some x values\n",
    "    x = np.arange(len(time_series))\n",
    "    # do a dataframe to drop NaNs\n",
    "    xy = pd.DataFrame(\n",
    "        {\"x\": x,\n",
    "        \"y\": time_series}\n",
    "    )\n",
    "    xy.dropna(inplace=True)\n",
    "    # reconvert\n",
    "    x = xy.x\n",
    "    y = xy.y \n",
    "\n",
    "    # do the fit\n",
    "    def tod_func(x, y0, amp, phi):\n",
    "        return y0 + amp * -np.cos(phi + x*np.pi/12)\n",
    "    params = curve_fit(tod_func, x, y)\n",
    "    [y0_fit, amp_fit, phi_fit] = params[0]\n",
    "\n",
    "    # exclude negative amplitudes -> convert to phase information\n",
    "    if amp_fit < 0:\n",
    "        amp_fit = abs(amp_fit)\n",
    "        phi_fit += np.pi\n",
    "\n",
    "    # get tod-angle between 0 and 2 pi\n",
    "    phi_fit = phi_fit % (2*np.pi)\n",
    "    if phi_fit < 0:\n",
    "        phi_fit += 2*np.pi\n",
    "    # calulate y_fit\n",
    "    y_fit = tod_func(x, y0_fit, amp_fit, phi_fit)\n",
    "    if return_fit_curve:\n",
    "        return [phi_fit, x, y, y_fit]\n",
    "    return phi_fit\n",
    "\n",
    "df[\"time_of_day_angle\"] = df.temp.apply(fit_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features for extracting summary statistics\n",
    "features=[\"temp\",\"precip\",\"rel_humidity\",\"wind_dir_x\",\"wind_dir_y\",\"wind_spd\",\"atmos_press\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for extracting the last recording of each feature\n",
    "def last(feature):\n",
    "    if not pd.isna(feature[-1]):\n",
    "        return feature[-1]\n",
    "    if pd.isna(feature[-1]) and not pd.isna(feature[-2]):\n",
    "        return feature[-2]\n",
    "    return feature[-25]\n",
    "\n",
    "# function extracting and appending the last recording of each feature\n",
    "def get_last(df,col_name):\n",
    "    df[\"last_\"+col_name]=df[col_name].apply(last)\n",
    "    return df \n",
    "\n",
    "# function returning only non-Null values (helper for aggregation function)\n",
    "def remove_nan_values(case):\n",
    "    return [obs for obs in case if not math.isnan(obs)]\n",
    "\n",
    "# function for aggreating features\n",
    "def aggregate_features(df,col_name):\n",
    "    df[\"mean_\"+col_name]=df[col_name].apply(np.mean)\n",
    "    df[\"std_\"+col_name]=df[col_name].apply(np.std)\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get last value for each time series\n",
    "for col_name in features:\n",
    "    df=get_last(df,col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NaNs from dataframe before calculating aggregated metrics\n",
    "for col_name in features:\n",
    "    df[col_name]=df[col_name].apply(remove_nan_values)\n",
    "    df=aggregate_features(df,col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove columns with too many missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recording periods contain varying degrees of NaNs: compute percent NaN for each recording period and feature\n",
    "# function to compute the percentage of NaNs per recording period\n",
    "def compute_percent_nan(df, col_name):\n",
    "    df['percent_nan_'+col_name] = df[col_name].apply(lambda x: np.isnan(np.array(x)).sum()/len(x)*100)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate percentage of missings per recording period and feature and append to dataframe\n",
    "nan_columns = []\n",
    "for col_name in features:\n",
    "    df=compute_percent_nan(df,col_name)\n",
    "    nan_columns.append('percent_nan_'+col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaNs\n",
    "# filter observations based on percent NaN and check again the data distribution of the target and summary features\n",
    "df = df[(df[nan_columns]<30).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop raw sensor data contained as list from the initial dataset\n",
    "df.drop(labels=features,axis=1,inplace=True)\n",
    "\n",
    "#drop nan-columns\n",
    "df.drop(labels=nan_columns,axis=1,inplace=True)\n",
    "\n",
    "#drop ID column\n",
    "df.drop(labels='ID',axis=1,inplace=True)\n",
    "\n",
    "#drop missings from 'last observation' columns\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get target and feature columns w/o location\n",
    "colnames = df.columns.to_list()[1::] # get columns w/o location column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/air_quality_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a74321acea7b933ac2b40f4839998b763c182e4cba40b24760128a90b96880fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
