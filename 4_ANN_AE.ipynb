{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35455b7",
   "metadata": {},
   "source": [
    "# Forecasting Ugandan Air Quality using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f967c6d",
   "metadata": {},
   "source": [
    "# Module loading\n",
    "Load all the necessary packages for your assignment. We give you some modules in advance, feel free to add more, if you need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b25ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q git+https://github.com/tensorflow/docs\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f7b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "rseed = 42\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "plt.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a12ef62",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "Load here your data from your ML project. You can use either `pandas` or `numpy` to format your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c481ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Data\n",
    "df=pd.read_csv(\"./data/air_quality_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7414213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a12ef62",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Train-Test-Split and dummy encoding (if necessary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dd8f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "print(f\"We have {X.shape[0]} observations in our dataset and {X.shape[1]} features\")\n",
    "print(f\"Our target vector has also {y.shape[0]} values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4951932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy-encode the location feature\n",
    "location = pd.get_dummies(X['location'], prefix='location',drop_first=True)\n",
    "location.head()\n",
    "# concatenate dummy-encoded locations feature to original dataframe\n",
    "X = pd.concat([X, location],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0363c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=X['location'], random_state=rseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop multiclass location column and store in new variable to be used for color-coding residual plot\n",
    "X_train_loc = X_train.location\n",
    "X_test_loc = X_test.location\n",
    "X_train.drop('location', axis=1, inplace=True)\n",
    "X_test.drop('location', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac737e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract numeric features for z-standardization\n",
    "num_features = list(X_train.columns[X_train.dtypes=='float64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc8725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale features using z-transformation\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit_transform training training data\n",
    "X_train[num_features] = scaler.fit_transform(X_train[num_features])\n",
    "# apply transform to test data\n",
    "X_test[num_features] = scaler.transform(X_test[num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a9f18d",
   "metadata": {},
   "source": [
    "## DNN without regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7570f235",
   "metadata": {},
   "source": [
    "### Define model architecture and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b76a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture and compile in function\n",
    "def get_compiled_model():\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(64,kernel_initializer = 'uniform', activation='relu', input_dim = 26),\n",
    "      tf.keras.layers.Dense(64,kernel_initializer = 'uniform', activation='relu'),\n",
    "      tf.keras.layers.Dense(64,kernel_initializer = 'uniform', activation='relu'),\n",
    "      tf.keras.layers.Dense(64,kernel_initializer = 'uniform', activation='relu'),\n",
    "      tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.01, name='Adam'),\n",
    "                  loss='mae',\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3b9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate small model and print model summary\n",
    "with tf.device('/cpu:0'):\n",
    "    dnn_wo = get_compiled_model()\n",
    "    print(dnn_wo.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741fc9d5",
   "metadata": {},
   "source": [
    "### Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d01a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "with tf.device('/cpu:0'):\n",
    "    train_history_dnn_wo = dnn_wo.fit(X_train,\n",
    "                        y_train,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=1,\n",
    "                        batch_size = 48,\n",
    "                        epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a12a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function for training metrics\n",
    "def plot_training_metrics(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8))\n",
    "    ax1.plot(history.history['root_mean_squared_error'], label='Training Set', c='blue')\n",
    "    ax1.plot(history.history['val_root_mean_squared_error'], label='Validation Set', c='red')\n",
    "    ax1.set_yticks(ticks=np.arange(0,81, 20), labels=np.arange(0,81, 20), fontsize=12)\n",
    "    ax1.set_xticks(ticks=np.arange(0,200, 20), labels=np.arange(0,200, 20), fontsize=12)\n",
    "    ax1.set_title('Change in RMSE across training epochs', fontsize=16)\n",
    "    ax1.legend(fontsize=12)\n",
    "    ax1.set_ylabel('RMSE', fontsize=14)\n",
    "    ax1.set_xlabel('Epoch', fontsize=14)\n",
    "\n",
    "    ax2.plot(history.history['loss'], label='Training Set', c='blue')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Set', c='red')\n",
    "    ax2.set_yticks(ticks=np.arange(0,81, 20), labels=np.arange(0,81, 20), fontsize=12)\n",
    "    ax2.set_xticks(ticks=np.arange(0,201, 20), labels=np.arange(0,201, 20), fontsize=12)\n",
    "    ax2.set_title('\\nChange in Loss across training epochs', fontsize=16)\n",
    "    ax2.legend(fontsize=12)\n",
    "    ax2.set_ylabel('Loss (MAE)', fontsize=14)\n",
    "    ax2.set_xlabel('Epoch', fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16533c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history \n",
    "plot_training_metrics(train_history_dnn_wo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6328c9dc",
   "metadata": {},
   "source": [
    "### Evaluate model performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ddd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test set using .evaluate\n",
    "loss, rmse = dnn_wo.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Model RMSE: {rmse}')\n",
    "print('--------'*5)\n",
    "\n",
    "# Predict values for test set and flatten to 1 dimension\n",
    "y_pred_dnn_wo = dnn_wo.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b56a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate residuals\n",
    "residual_dnn_wo = y_test - y_pred_dnn_wo\n",
    "\n",
    "# compute mean of residuals\n",
    "np.mean(residual_dnn_wo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11722e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "sns.scatterplot(x=y_pred_dnn_wo, y=residual_dnn_wo, hue=X_test_loc)\n",
    "plt.xlabel('y_pred')\n",
    "plt.ylabel('residual')\n",
    "plt.title('Residual plot from DNN w/o regularization');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82b319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "sns.scatterplot(x=y_pred_dnn_wo, y=y_test, color='b')#, hue=X_test_loc)\n",
    "plt.xlabel('Predicted from Weather Data (in µg / m$^3$)')\n",
    "plt.ylabel('Measured (in µg / m$^3$)')\n",
    "plt.title('Measured and Predicted PM$_{2.5}$ Concentration');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027e04e3",
   "metadata": {},
   "source": [
    "### Convert actual and predicted PM2.5 levels from best models into air quality categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07977eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting function for color-coded confusion matrix\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    Source: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.figure(figsize = (6, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, size = 16)\n",
    "    plt.colorbar(aspect=4)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, size = 10)\n",
    "    plt.yticks(tick_marks, classes, size = 10)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    # Labeling the plot\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), fontsize = 12,\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Measured Category', size = 14)\n",
    "    plt.xlabel('Predicted Category', size = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb596556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual y labels\n",
    "y_test_labels = ['Good' if x < 13 else 'Moderate' if x < 36 else 'Unhealthy (Sensitive)' if x < 56 else 'Unhealthy' if x < 151 \n",
    "                    else 'Very Unhealthy' if x < 251 else 'Hazardous' for x in y_test]\n",
    "\n",
    "# predicted y labels by XGBoost Regressor\n",
    "y_pred_labels_dnn_wo = ['Good' if x < 13 else 'Moderate' if x < 36 else 'Unhealthy (Sensitive)' if x < 56 else 'Unhealthy' if x < 151 \n",
    "                            else 'Very Unhealthy' if x < 251 else 'Hazardous' for x in y_pred_dnn_wo]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30ebf9f",
   "metadata": {},
   "source": [
    "### Compute confusion matrix and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff76bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_wo = confusion_matrix(y_test_labels, y_pred_labels_dnn_wo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5043c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm_wo, classes=['Good', 'Moderate', 'Unhealthy\\n(Sensitive)', 'Unhealthy', 'Very Unhealthy', 'Hazardous'],\n",
    "                title='Confusion Matrix - DNN w/o regularization');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58189161",
   "metadata": {},
   "source": [
    "## DNN with L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7570f235",
   "metadata": {},
   "source": [
    "### Define model architecture and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba16292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture and compile in function\n",
    "def get_compiled_l2model():\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(64,kernel_initializer = 'uniform', kernel_regularizer=tf.keras.regularizers.L2(0.01), activation='relu', input_dim = 26),\n",
    "      tf.keras.layers.Dense(64,kernel_initializer = 'uniform', kernel_regularizer=tf.keras.regularizers.L2(0.01), activation='relu'),\n",
    "      tf.keras.layers.Dense(64,kernel_initializer = 'uniform', kernel_regularizer=tf.keras.regularizers.L2(0.01), activation='relu'),\n",
    "      tf.keras.layers.Dense(64,kernel_initializer = 'uniform', kernel_regularizer=tf.keras.regularizers.L2(0.01), activation='relu'),\n",
    "      tf.keras.layers.Dense(1,kernel_initializer = 'uniform')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.01, name='Adam'),\n",
    "                  loss='mae',\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0f8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate small model and print model summary\n",
    "with tf.device('/cpu:0'):\n",
    "    dnn_l2 = get_compiled_l2model()\n",
    "    print(dnn_l2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8371b5",
   "metadata": {},
   "source": [
    "### Fit the model to the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d61596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "with tf.device('/cpu:0'):\n",
    "    train_history_dnn_l2 = dnn_l2.fit(X_train,\n",
    "                        y_train,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=1,\n",
    "                        batch_size = 48,\n",
    "                        epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe93ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history \n",
    "plot_training_metrics(train_history_dnn_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6743069b",
   "metadata": {},
   "source": [
    "### Evaluate model performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e56e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test set using .evaluate\n",
    "loss, rmse = dnn_l2.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Model RMSE: {rmse}')\n",
    "print('--------'*5)\n",
    "\n",
    "# Predict values for test set and flatten to 1 dimension\n",
    "y_pred_dnn_l2 = dnn_l2.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29353e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate residuals\n",
    "residual_dnn_l2 = y_test - y_pred_dnn_l2\n",
    "\n",
    "# compute mean of residuals\n",
    "np.mean(residual_dnn_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8635a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "sns.scatterplot(x=y_pred_dnn_l2, y=residual_dnn_l2, hue=X_test_loc)\n",
    "plt.xlabel('y_pred')\n",
    "plt.ylabel('residual')\n",
    "plt.title('Residual plot from DNN with L2 regularization');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48add985",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "sns.scatterplot(x=y_pred_dnn_l2, y=y_test, color='b')#, hue=X_test_loc)\n",
    "plt.xlabel('Predicted from Weather Data (in µg / m$^3$)')\n",
    "plt.ylabel('Measured (in µg / m$^3$)')\n",
    "plt.title('Measured and Predicted PM$_{2.5}$ Concentration');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026991e5",
   "metadata": {},
   "source": [
    "### Convert predicted PM2.5 concentrations into labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14572f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted y labels by XGBoost Regressor\n",
    "y_pred_labels_dnn_l2 = ['Good' if x < 13 else 'Moderate' if x < 36 else 'Unhealthy (Sensitive)' if x < 56 else 'Unhealthy' if x < 151 \n",
    "                            else 'Very Unhealthy' if x < 251 else 'Hazardous' for x in y_pred_dnn_l2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf400f",
   "metadata": {},
   "source": [
    "### Compute confusion matrix and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01233a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_l2 = confusion_matrix(y_test_labels, y_pred_labels_dnn_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm_l2, classes=['Good', 'Moderate', 'Unhealthy\\n(Sensitive)', 'Unhealthy', 'Very Unhealthy', 'Hazardous'],\n",
    "                title='Confusion Matrix - DNN with L2 regularization');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f7cc10",
   "metadata": {},
   "source": [
    "## Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_wo.save('models/dnn_wo')\n",
    "dnn_l2.save('models/dnn_l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202431d7",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The dnn currently does not peform better than XGBoost Regressor. The L2 regularization did not improve the prediction accuracy on the test set. Testing different model architectures and/or optimizers may further improve dnn model accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a74321acea7b933ac2b40f4839998b763c182e4cba40b24760128a90b96880fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
